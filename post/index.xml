<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Born Too Late</title>
    <link>https://blog.yuyat.jp/post/</link>
    <description>Recent content in Posts on Born Too Late</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Sun, 04 Dec 2016 23:47:21 +0900</lastBuildDate>
    <atom:link href="https://blog.yuyat.jp/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>BigQuery の標準 SQL モードで日付テーブルのフィルタリング、または Re:dash の Query Snippets を活用する話</title>
      <link>https://blog.yuyat.jp/post/filtering-tables-in-bigquery-standard-sql/</link>
      <pubDate>Sun, 04 Dec 2016 23:47:21 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/filtering-tables-in-bigquery-standard-sql/</guid>
      <description>&lt;p&gt;要は Legacy SQL モード で &lt;code&gt;FROM (TABLE_DATE_RANGE(dataset.table_, TIMESTAMP(&#39;2016-01-01&#39;), TIMESTAMP(&#39;2016-01-14&#39;)))&lt;/code&gt; とか書いていたのを標準 SQL でどう書くか、という話です。&lt;br /&gt;
すぐ忘れるのでメモ。&lt;/p&gt;

&lt;p&gt;テーブルは以下のような名前になっている前提です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;table_20160101&lt;/li&gt;
&lt;li&gt;table_20160102&lt;/li&gt;
&lt;li&gt;table_20160103&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これで例えば直近 14 日分のテーブルを対象にしたい場合はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT time
FROM `dataset.table_*`
WHERE _TABLE_SUFFIX &amp;gt;= FORMAT_DATE(&#39;%Y%m%d&#39;, DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テーブル名はワイルドカードで指定しつつ、&lt;code&gt;_TABLE_SUFFIX&lt;/code&gt; という擬似カラムに対して日付の条件を指定する。&lt;/p&gt;

&lt;p&gt;詳細は以下の公式ドキュメントを参考にしましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/bigquery/docs/wildcard-tables#wildcard_table_syntax&#34;&gt;Wildcard table syntax&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;よく使うパターンですが、覚えていられない、という人で普段 &lt;a href=&#34;https://redash.io/&#34;&gt;Re:dash&lt;/a&gt; でクエリを書いている、という人は &lt;a href=&#34;https://github.com/getredash/redash/blob/master/CHANGELOG.md#v0120---2016-11-20&#34;&gt;v0.12.0&lt;/a&gt; で追加された Query Snippets という機能を使うと、こんな感じにキーワード補完されるようになって便利です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/filtering-tables-in-bigquery-standard-sql/query_snippets.gif&#34; alt=&#34;query snippets&#34; /&gt;&lt;/p&gt;

&lt;p&gt;設定としては以下のようにしておけば &lt;code&gt;_TABLE_SUFFIX&lt;/code&gt; というキーワードをトリガーに補完されます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/filtering-tables-in-bigquery-standard-sql/setting.png&#34; width=&#34;658&#34; height=&#34;257&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GitHub の Issue を作るコマンド ghissue を作った</title>
      <link>https://blog.yuyat.jp/post/ghissue-a-command-to-create-github-issues/</link>
      <pubDate>Sun, 27 Nov 2016 02:43:58 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/ghissue-a-command-to-create-github-issues/</guid>
      <description>

&lt;p&gt;作りました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yuya-takeyama/ghissue&#34;&gt;yuya-takeyama/ghissue&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;なぜ作ったか&#34;&gt;なぜ作ったか&lt;/h2&gt;

&lt;p&gt;いろいろな自動化スクリプトを書く中で、&lt;a href=&#34;https://octokit.github.io/&#34;&gt;Octokit&lt;/a&gt; とかで毎回実装するのは面倒だったので、標準入力だけ食わせればいい感じにやってくれるものが欲しいな、と思って作りました。&lt;/p&gt;

&lt;p&gt;タイトル・本文だけを標準出力に書き出すスクリプトだけ書けば、それをパイプで繋げるだけで ghissue が Issue を立ててくれます。&lt;br /&gt;
タイトル・本文だけうまく組み立てることに集中すればよくなり、テストも楽になるでしょう。&lt;/p&gt;

&lt;p&gt;類似ツールとしては &lt;a href=&#34;https://github.com/stephencelis/ghi&#34;&gt;ghi&lt;/a&gt; というツールがありますが、これは標準入力からタイトル・本文を指定することができないので、他のコマンドと組み合わせて使うのはやや面倒です。&lt;br /&gt;
また、ghi が Ruby なのに対して、ghissue は Go で実装されていてコンパイル済みのバイナリも GitHub からダウンロードできます。&lt;/p&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;h3 id=&#34;アクセストークンの指定&#34;&gt;アクセストークンの指定&lt;/h3&gt;

&lt;p&gt;GitHub のアクセストークンを &lt;code&gt;GITHUB_ACCESS_TOKEN&lt;/code&gt; という環境変数で指定します。&lt;/p&gt;

&lt;h3 id=&#34;issue-を作る&#34;&gt;Issue を作る&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ some_command | ghissue yuya-takeyama/test --labels Bug,Major --assignees yuya-takeyama
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;some_command&lt;/code&gt; は Issue のタイトル・本文を生成するためのコマンドです。&lt;br /&gt;
1 行目がタイトルになり、残りは本文になります。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--labels&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;) ではラベルを指定します。カンマ区切りで複数指定可能です。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--assignees&lt;/code&gt; (&lt;code&gt;-a&lt;/code&gt;) では assignee を指定します。これもカンマ区切りで複数指定可能です。&lt;/p&gt;

&lt;h2 id=&#34;その他&#34;&gt;その他&lt;/h2&gt;

&lt;p&gt;Issue を編集する機能・コメントを記入するための機能もあっていいだろうと思うものの、今のところ個人的には必要としてないので、まぁそのうち。&lt;/p&gt;

&lt;p&gt;よければご利用ください。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker コンテナを DigitalOcean 上でサクッと動かす</title>
      <link>https://blog.yuyat.jp/post/run-docker-container-in-digitalocean/</link>
      <pubDate>Tue, 11 Oct 2016 21:29:41 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/run-docker-container-in-digitalocean/</guid>
      <description>

&lt;h2 id=&#34;やりたいこと&#34;&gt;やりたいこと&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;任意のアプリの Docker コンテナをサクッと立ち上げたい&lt;/li&gt;
&lt;li&gt;かつグローバル IP アドレスを割り当てて外から接続したい&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;より具体的には、今回は &lt;code&gt;mitmproxy&lt;/code&gt; をインターネット上で動かして iPhone 等のスマートフォン端末からつなぎたかった、という感じです。&lt;/p&gt;

&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;

&lt;h3 id=&#34;digitalocean-のアカウントを作成する&#34;&gt;DigitalOcean のアカウントを作成する&lt;/h3&gt;

&lt;p&gt;ここは割愛。&lt;/p&gt;

&lt;h3 id=&#34;digitalocean-のアクセストークンを作成&#34;&gt;DigitalOcean のアクセストークンを作成&lt;/h3&gt;

&lt;p&gt;API -&amp;gt; Tokens -&amp;gt; Generate New Token から適当に名前をつけて作ります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/run-docker-container-in-digitalocean/generate-new-token.png&#34; width=&#34;608&#34; height=&#34;424&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;docker-machine-で-docker-環境を作る&#34;&gt;docker-machine で Docker 環境を作る&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker-machine&lt;/code&gt; のインストール手順については割愛。&lt;br /&gt;
Mac だと Homebrew でもインストールできるので適当にやっておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create --driver digitalocean --digitalocean-access-token=ACCESS_TOKEN --digitalocean-region=sgp1 mitmproxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--digitalocean-access-token&lt;/code&gt; には前の手順で作ったアクセストークンを指定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--digitalocean-region&lt;/code&gt; にはリージョンの slug を指定します。&lt;br /&gt;
省略すると New York にできてレイテンシが辛いので、日本からだとシンガポールでも指定しておくのがいいでしょう。&lt;/p&gt;

&lt;p&gt;リージョンの slug 一覧はこんな感じに最新版を取得できます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Authorization: Bearer ACCESS_TOKEN&amp;quot; &amp;quot;https://api.digitalocean.com/v2/regions&amp;quot; -s | jq &#39;.regions[] | &amp;quot;\(.slug)\t\(.name)&amp;quot;&#39; -r | sort
ams2    Amsterdam 2
ams3    Amsterdam 3
blr1    Bangalore 1
fra1    Frankfurt 1
lon1    London 1
nyc1    New York 1
nyc2    New York 2
nyc3    New York 3
sfo1    San Francisco 1
sfo2    San Francisco 2
sgp1    Singapore 1
tor1    Toronto 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;末尾の &lt;code&gt;mitmproxy&lt;/code&gt; という部分は Docker 環境に任意の名前をつけるだけなので適当に。&lt;/p&gt;

&lt;p&gt;数分かかりますがトイレ行ってコーヒーでも淹れて来たりすれば終わっているでしょう。&lt;/p&gt;

&lt;h3 id=&#34;docker-コンテナの起動&#34;&gt;Docker コンテナの起動&lt;/h3&gt;

&lt;p&gt;Dockerfile を拾ってこれるような場合は Docker Hub のページ見ながら適当に。&lt;br /&gt;
信頼していい Dockerfile なのかは注意する。&lt;/p&gt;

&lt;p&gt;今回は &lt;a href=&#34;https://hub.docker.com/r/mitmproxy/mitmproxy/&#34;&gt;mitmproxy/mitmproxy&lt;/a&gt; のイメージを使いました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Docker への接続情報をターミナルのセッションに読み込む
$ eval $(docker-machine env mitmproxy)

# Docker コンテナの起動
$ docker run --rm -it -p 8080:8080 mitmproxy/mitmproxy
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ip-アドレスの確認&#34;&gt;IP アドレスの確認&lt;/h3&gt;

&lt;p&gt;今回は外部から接続する前提なので。&lt;br /&gt;
DigitalOcean の Droplets の一覧から見てもいいです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine ip mitmproxy
128.199.***.***
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;docker-環境を削除する&#34;&gt;Docker 環境を削除する&lt;/h3&gt;

&lt;p&gt;使い捨て前提なので削除しておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine rm mitmproxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アクセストークンも DigitalOcean のページ上から削除しておくとより安心でしょう。&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;こういうシュッとサーバなりコンテナなり必要なとき DigitalOcean は便利なのでアカウントを持っていない人は&lt;a href=&#34;https://m.do.co/c/645fac0c10f9&#34;&gt;作っておきましょう。 (アフィリエイトリンク)&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker のメトリクスを Re:dash でビジュアライズ</title>
      <link>https://blog.yuyat.jp/post/visualize-docker-metrics-with-redash/</link>
      <pubDate>Sun, 02 Oct 2016 14:56:46 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/visualize-docker-metrics-with-redash/</guid>
      <description>

&lt;p&gt;しばらく前から &lt;a href=&#34;http://dokku.viewdocs.io/dokku/&#34;&gt;Dokku&lt;/a&gt; という Docker ベースの Heroku ライクな PaaS 基盤を趣味で運用していて、その中で旧ブログの WordPress や 自分用のツールなんかを動かしたりしている。&lt;/p&gt;

&lt;p&gt;サーバのメトリクス収集には &lt;a href=&#34;https://mackerel.io/&#34;&gt;Mackerel&lt;/a&gt; を利用しているが、Docker コンテナ単位での計測は行っていなかった。&lt;br /&gt;
Mackerel はホスト数に応じた課金を行っていて、5 ホストまでは無料だが、コンテナまで追加してしまうとすぐにその枠を溢れてしまう。&lt;/p&gt;

&lt;p&gt;というわけで簡単な仕組みを自分で用意いてみた。&lt;/p&gt;

&lt;h2 id=&#34;できたもの&#34;&gt;できたもの&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/visualize-docker-metrics-with-redash/chart.png&#34; width=&#34;414&#34; height=&#34;319&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/visualize-docker-metrics-with-redash/stack-chart.png&#34; width=&#34;416&#34; height=&#34;342&#34;&gt;&lt;/p&gt;

&lt;p&gt;どちらもメモリ使用量 (MB) をコンテナ名ごとにグラフ化したもので、どちらもデータは同じものを使っている。&lt;br /&gt;
後者はグラフを積み上げることでコンテナ全体で使用しているメモリの使用量もわかるようになっている。&lt;/p&gt;

&lt;p&gt;今のところ Docker のリソースに関して困っているのはメモリだけなので、とりあえずはこれだけ。&lt;/p&gt;

&lt;p&gt;なお、Dokku ではコンテナ名が &lt;code&gt;アプリ名.プロセス名.プロセス番号&lt;/code&gt; という感じになる (例えば &lt;code&gt;blog.web.1&lt;/code&gt; といった具合) になるので、アプリを再起動してコンテナ ID が変わっても連続的にモニタリングできる。&lt;br /&gt;
グラフ中異常値っぽいのが出ているところはまさにアプリを再起動したりしているところ。&lt;/p&gt;

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;p&gt;以下のような流れでこのグラフを作り出している。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kiyoto/fluent-plugin-docker-metrics&#34;&gt;fluent-plugin-docker-metrics&lt;/a&gt; で Docker のメトリクスを td-agent に収集&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaizenplatform/fluent-plugin-bigquery&#34;&gt;fluent-plugin-bigquery&lt;/a&gt; でメトリクスを BigQuery に送信&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://redash.io/&#34;&gt;Re:dash&lt;/a&gt; で BigQuery 上のデータをグラフ化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;

&lt;h3 id=&#34;fluent-plugin-docker-metrics-のセットアップ&#34;&gt;fluent-plugin-docker-metrics のセットアップ&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;td-agent.conf&lt;/code&gt; の設定はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type docker_metrics
  stats_interval 1m
  tag_prefix docker.metrics
&amp;lt;/source&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tag_prefix&lt;/code&gt; はデフォルトだと &lt;code&gt;docker&lt;/code&gt; だが、別の機会で Docker の何かを収集することもあるかもしれないので &lt;code&gt;docker.metrics&lt;/code&gt; としてみた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;stats_interval&lt;/code&gt; はとりあえず 1 分ごとにしているが、すべてのコンテナの値を収集するとデータ量がそこそこ多くなるので 5 分ごととかに減らしてもいいかもしれない。&lt;/p&gt;

&lt;p&gt;これでこんな感じのデータが収集できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;20161002T062409+0000	docker.metrics.memory.stat	{&amp;quot;key&amp;quot;:&amp;quot;memory_stat_cache&amp;quot;,&amp;quot;value&amp;quot;:9039872,&amp;quot;type&amp;quot;:&amp;quot;gauge&amp;quot;,&amp;quot;hostname&amp;quot;:&amp;quot;HOSTNAME&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6008f80ef7f6c6747edf01019846074d27e29a7d217c6e3f3301fcdb435cef73&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;/blog-legacy.web.1&amp;quot;}
20161002T062409+0000	docker.metrics.memory.stat	{&amp;quot;key&amp;quot;:&amp;quot;memory_stat_rss&amp;quot;,&amp;quot;value&amp;quot;:14028800,&amp;quot;type&amp;quot;:&amp;quot;gauge&amp;quot;,&amp;quot;hostname&amp;quot;:&amp;quot;HOSTNAME&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6008f80ef7f6c6747edf01019846074d27e29a7d217c6e3f3301fcdb435cef73&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;/blog-legacy.web.1&amp;quot;}
20161002T062409+0000	docker.metrics.memory.stat	{&amp;quot;key&amp;quot;:&amp;quot;memory_stat_rss_huge&amp;quot;,&amp;quot;value&amp;quot;:0,&amp;quot;type&amp;quot;:&amp;quot;gauge&amp;quot;,&amp;quot;hostname&amp;quot;:&amp;quot;HOSTNAME&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6008f80ef7f6c6747edf01019846074d27e29a7d217c6e3f3301fcdb435cef73&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;/blog-legacy.web.1&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナ ID とコンテナ名の両方が記録されるので、どちらでもグループ化して集計することが可能である。&lt;/p&gt;

&lt;h3 id=&#34;fluent-plugin-bigquery-のセットアップ&#34;&gt;fluent-plugin-bigquery のセットアップ&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match docker.metrics.**&amp;gt;
  @type bigquery

  auth_method json_key
  email ***@PROJECT.iam.gserviceaccount.com
  json_key /etc/td-agent/bigquery/key.json

  project PROJECT
  dataset docker
  table   metrics_%Y%m%d
  ignore_unknown_values true
  auto_create_table true

  time_format %s
  time_field time

  field_timestamp time
  field_integer   value
  field_string    key,type,hostname,id,name
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;日別にテーブルに保存されるよう、&lt;code&gt;table&lt;/code&gt; は &lt;code&gt;metrics_%Y%m%d&lt;/code&gt; としている。&lt;/p&gt;

&lt;p&gt;また、テーブルは自動で作られるが、データセットはあらかじめ作っておく必要があるらしい。&lt;/p&gt;

&lt;h3 id=&#34;re-dash-でグラフ化&#34;&gt;Re:dash でグラフ化&lt;/h3&gt;

&lt;p&gt;Re:dash 自体のセットアップについては割愛するが、個人的にはこれを Dokku で動かしていて、その手順については以前 Qiita に書いている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/yuya_takeyama/items/9915f5ae3953a9c2c14b&#34;&gt;Dokku に Re:dash をインストールする&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;クエリはこんな感じ。&lt;br /&gt;
Standard SQL を使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
  time,
  name,
  value / 1024 / 1024 AS size
FROM
  `PROJECT.docker.metrics_*`
WHERE
  key = &#39;memory_stat_rss&#39;
ORDER BY
  name,
  time
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とりあえず全データを対象にしているが、データ量が増えてきたらテーブル名を日付で絞ったほうが良いかもしれない。&lt;/p&gt;

&lt;p&gt;あとは適当に Visualize の設定を行う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/visualize-docker-metrics-with-redash/chart-setting.png&#34; width=&#34;531&#34; height=&#34;608&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/visualize-docker-metrics-with-redash/stack-setting.png&#34; width=&#34;526&#34; height=&#34;607&#34;&gt;&lt;/p&gt;

&lt;p&gt;これで先に載せた感じのグラフが出来上がる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/visualize-docker-metrics-with-redash/chart.png&#34; width=&#34;414&#34; height=&#34;319&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/visualize-docker-metrics-with-redash/stack-chart.png&#34; width=&#34;416&#34; height=&#34;342&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;グラフ化した結果、メモリを一番使っているのは Re:dash の Worker だということがわかった。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【RMP×Quipper】Food&amp;Drink meetup #3 で発表した</title>
      <link>https://blog.yuyat.jp/post/rmp-quipper-food-and-drink-meetup/</link>
      <pubDate>Sat, 01 Oct 2016 16:41:07 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/rmp-quipper-food-and-drink-meetup/</guid>
      <description>&lt;p&gt;Quipper とその親会社であるところのリクルートマーケティングパートナーズ (RMP) とでの&lt;a href=&#34;http://rmp-quipper.connpass.com/event/39082/&#34;&gt;合同イベント&lt;/a&gt; (平たくいうと採用イベント) があって、LT の発表枠が空いていたので発表してきた。&lt;/p&gt;

&lt;p&gt;スライドは Qiita のスライド機能を初めて使ってみた。&lt;br /&gt;
スクリーンに写すと文字が結構小さかったので、事前のチェックが大事だと思った。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/yuya_takeyama/items/6b0fe4bc7d501f69e081&#34;&gt;curl でサッとベンチマークをとる (スライド版)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;内容的には以前同じく &lt;a href=&#34;http://qiita.com/yuya_takeyama/items/baf48a3f643e743a46b4&#34;&gt;Qiita に書いた記事&lt;/a&gt; を加筆・再編集した程度のものなので、準備にはあまり時間がかかっていない。&lt;/p&gt;

&lt;p&gt;Google Chrome の Developer Tools からリクエストを curl コマンドとしてコピーする機能について知らない人が意外と多かったので、その点が一番バリュー高かったのかもしれない。&lt;/p&gt;

&lt;p&gt;あとは見つけた時に超クールだと思った &lt;a href=&#34;https://github.com/winebarrel/hyst&#34;&gt;hyst&lt;/a&gt; というツールについても軽く紹介した。&lt;br /&gt;
hyst を作っている &lt;a href=&#34;https://github.com/winebarrel&#34;&gt;@winebarrel&lt;/a&gt; さんには &lt;a href=&#34;https://github.com/winebarrel/miam&#34;&gt;miam&lt;/a&gt; や &lt;a href=&#34;https://github.com/winebarrel/roadworker&#34;&gt;roadworker&lt;/a&gt; でもお世話になっています。&lt;br /&gt;
あと &lt;a href=&#34;http://hakobera.hatenablog.com/entry/2016/03/02/084204&#34;&gt;Quipper でも使われているみたい&lt;/a&gt;です。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>curl でレスポンスタイムをシュッと取るヤツ</title>
      <link>https://blog.yuyat.jp/post/stuff-to-get-response-time-with-curl/</link>
      <pubDate>Tue, 27 Sep 2016 09:10:34 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/stuff-to-get-response-time-with-curl/</guid>
      <description>&lt;p&gt;以前 Qiita に&lt;a href=&#34;http://qiita.com/yuya_takeyama/items/baf48a3f643e743a46b4&#34;&gt;curl でサッと HTTP ベンチマーク&lt;/a&gt;と書いたが、それをもうちょい簡単にやるために以下のようなコマンドを用意してみた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;#!/bin/sh
curl -s -o /dev/null -w &#39;%{time_starttransfer}\n&#39; &amp;quot;$@&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを &lt;code&gt;curlb&lt;/code&gt; という名前で &lt;code&gt;$PATH&lt;/code&gt; の通ったところに置いておくと以下のようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curlb https://blog.yuyat.jp/
0.067
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>標準エラー出力に tee するコマンド tee2err を作った</title>
      <link>https://blog.yuyat.jp/post/tee2err/</link>
      <pubDate>Mon, 26 Sep 2016 01:00:24 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/tee2err/</guid>
      <description>

&lt;p&gt;GNU tee でも BSD tee でもできないので作りました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/yuya-takeyama/tee2err&#34;&gt;yuya-takeyama/tee2err&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;これは何か&#34;&gt;これは何か&lt;/h2&gt;

&lt;p&gt;標準入力を食わせると、標準出力と標準エラー出力に同じものを出力するだけのコマンドです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo foo | tee2err
foo
foo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;foo と 2 回出力されていますが、一方は標準出力に、もう一方は標準エラー出力に出力されています。&lt;/p&gt;

&lt;h2 id=&#34;どういう時に使うか&#34;&gt;どういう時に使うか&lt;/h2&gt;

&lt;p&gt;標準入力からストリームを食わせるとなんらかの終端操作を行うようなツールと一緒に使います。&lt;/p&gt;

&lt;p&gt;例えば 1 から 10 までの数列の総和を求める場合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ seq 10 | perl -ane &#39;$i+=$_; END { print &amp;quot;SUM: $i\n&amp;quot;; }&#39;
SUM: 55
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはこれで特に問題ないですが、これに &lt;code&gt;tee2err&lt;/code&gt; を組み合わせるとこのようになります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ seq 10 | tee2err | perl -ane &#39;$i+=$_; END { print &amp;quot;SUM: $i\n&amp;quot;; }&#39;
1
2
3
4
5
6
7
8
9
10
SUM: 55
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;seq 10&lt;/code&gt; の出力を見ながら計算結果を待つことができます。&lt;br /&gt;
1 ~ 10 の数値は標準エラー出力への出力なので、&lt;code&gt;perl&lt;/code&gt; での計算に影響は及ぼしません。&lt;/p&gt;

&lt;p&gt;この例であればいずれにせよ一瞬で終わるので特に問題にならないですが、以前 Qiita に書いた &lt;a href=&#34;http://qiita.com/yuya_takeyama/items/baf48a3f643e743a46b4&#34;&gt;&lt;code&gt;curl&lt;/code&gt; コマンドでベンチマークを実行するような場合&lt;/a&gt;だとそれなりに待たされるので、ターミナルに何も出力されないまま待ち続けるのは少しストレスだったりするので作りました。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/yuya-takeyama/tee2err
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;または &lt;a href=&#34;https://github.com/yuya-takeyama/tee2err/releases&#34;&gt;releases&lt;/a&gt; にビルド済みバイナリも置いてます。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GitHub Pages を nginx のリバースプロキシ越しに配信する</title>
      <link>https://blog.yuyat.jp/post/serving-github-pages-through-reverse-proxy/</link>
      <pubDate>Sun, 25 Sep 2016 17:57:40 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/serving-github-pages-through-reverse-proxy/</guid>
      <description>

&lt;p&gt;このブログは&lt;a href=&#34;https://blog.yuyat.jp/post/auto-deploy-hugo-to-github-pages-with-circleci/&#34;&gt;以前の記事&lt;/a&gt;にも書いた通り、&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt; から配信しています。&lt;/p&gt;

&lt;p&gt;そしてさらに、前段に nginx のリバースプロキシを置いた構成になってます。&lt;/p&gt;

&lt;h2 id=&#34;何故リバースプロキシを利用するか&#34;&gt;何故リバースプロキシを利用するか&lt;/h2&gt;

&lt;p&gt;はっきり言って普通に考えたら無駄感はありますが、良い点をいくつか挙げてみます。&lt;/p&gt;

&lt;h3 id=&#34;zone-apex-domain-を使用することができる&#34;&gt;Zone apex domain を使用することができる&lt;/h3&gt;

&lt;p&gt;GitHub Pages は CNAME による Custom domain に対応していますが、CNAME では通常 Zone apex domain に対応することができません。&lt;/p&gt;

&lt;p&gt;リバースプロキシを利用することで、ドメインの A レコードにリバースプロキシを指定し、その upstream に GitHub Pages の URL を指定することで、対応することができます。&lt;/p&gt;

&lt;p&gt;(このブログはご覧の通り Zone apex domain ではないですが、そのうちそっちにもページを作るつもりです)&lt;/p&gt;

&lt;h3 id=&#34;custom-domain-でも-https-を使用することができる&#34;&gt;Custom domain でも HTTPS を使用することができる&lt;/h3&gt;

&lt;p&gt;GitHub Pages はデフォルトでは USERNAME.github.io ドメインが割り当てられ、HTTPS で配信されます。&lt;/p&gt;

&lt;p&gt;ですが、CNAME を使った場合は HTTP となってしまい、HTTPS を利用する方法は GitHub からは提供されていません。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.yuyat.jp/post/auto-renew-letsencrypt-cert-keys-with-ansible-and-certbot/&#34;&gt;Let&amp;rsquo;s Encrypt&lt;/a&gt; を使えばセットアップは簡単です。&lt;/p&gt;

&lt;h3 id=&#34;アクセスログをちゃんと取得できる&#34;&gt;アクセスログをちゃんと取得できる&lt;/h3&gt;

&lt;p&gt;GitHub でもリポジトリの Graphs -&amp;gt; Traffic を見るとある程度わかりますが、nginx で好きなログを残せるようになります。&lt;/p&gt;

&lt;h2 id=&#34;設定手順&#34;&gt;設定手順&lt;/h2&gt;

&lt;h3 id=&#34;github-上で-custom-domain-の設定をする&#34;&gt;GitHub 上で Custom domain の設定をする&lt;/h3&gt;

&lt;p&gt;これは必須というわけではないですが、やった方がいいと思うのでその前提で進めます。&lt;br /&gt;
設定しない場合、以降の設定手順も微妙に違ってくるので注意が必要です。&lt;/p&gt;

&lt;p&gt;Custom domain はいつからか Web の UI 上から設定が可能になっていたので、そこからやるのがお手軽です。&lt;br /&gt;
リポジトリの Settings -&amp;gt; Options からできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/serving-github-pages-through-reverse-proxy/custom-domain.png&#34; width=&#34;349&#34; height=&#34;125&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;nginx-の設定&#34;&gt;nginx の設定&lt;/h3&gt;

&lt;p&gt;HTTPS で配信する場合、おそらくこれが最小限の設定です。&lt;br /&gt;
(実際は &lt;code&gt;X-Forwarded-For&lt;/code&gt; とかも指定しているけど多分特に影響していない)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
  listen 443 ssl ;
  server_name blog.yuyat.jp;

  ssl_certificate     /etc/letsencrypt/live/blog.yuyat.jp/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/blog.yuyat.jp/privkey.pem;

  location / {
    proxy_pass https://yuya-takeyama.github.io;

    proxy_redirect http://blog.yuyat.jp https://blog.yuyat.jp;

    proxy_set_header Host $host;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意する必要があるのは &lt;code&gt;proxy_pass&lt;/code&gt; の URL です。&lt;br /&gt;
このブログの GitHub Pages 上の URL は本来 &lt;code&gt;https://yuya-takeyama.github.io/blog.yuyat.jp/&lt;/code&gt; ですが、リポジトリ名の部分は指定しません。&lt;/p&gt;

&lt;p&gt;その変わり、リポジトリ名は &lt;code&gt;proxy_set_header&lt;/code&gt; で &lt;code&gt;Host&lt;/code&gt; として指定します。&lt;br /&gt;
この場合はリポジトリ名がそのままドメイン名になっているので &lt;code&gt;$host&lt;/code&gt; を使っています。&lt;/p&gt;

&lt;p&gt;HTTPS の場合は &lt;code&gt;proxy_redirect&lt;/code&gt; も設定が必要です。&lt;br /&gt;
これは例えば &lt;code&gt;https://blog.yuyat.jp/post&lt;/code&gt; のような末尾のスラッシュを省略した URL にアクセスした場合リダイレクトが発生しますが、&lt;br /&gt;
その時に http にリダイレクトしてしまうのを防ぐために必要です。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Let&#39;s Encrypt の証明書を Ansible と certbot で Nginx にインストール &amp; 自動更新</title>
      <link>https://blog.yuyat.jp/post/auto-renew-letsencrypt-cert-keys-with-ansible-and-certbot/</link>
      <pubDate>Mon, 19 Sep 2016 14:12:38 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/auto-renew-letsencrypt-cert-keys-with-ansible-and-certbot/</guid>
      <description>

&lt;p&gt;これも&lt;a href=&#34;https://blog.yuyat.jp/post/brand-new-blog/&#34;&gt;リニューアル&lt;/a&gt;ネタです。&lt;/p&gt;

&lt;h2 id=&#34;やりたいこと&#34;&gt;やりたいこと&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Let&amp;rsquo;s Encrypt の証明書を Ansible でインストールする&lt;/li&gt;
&lt;li&gt;その後の証明書の更新も自動で行うようにする

&lt;ul&gt;
&lt;li&gt;その設定もやはり Ansible で行う&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;前提とする環境&#34;&gt;前提とする環境&lt;/h2&gt;

&lt;p&gt;Ubuntu 16.04 だと certbot が apt-get でインストールできますが、それ未満だと &lt;a href=&#34;https://certbot.eff.org/all-instructions/#ubuntu-14-04-trusty-apache&#34;&gt;certbot-auto&lt;/a&gt; というコマンドを手動でインストールする必要があります。&lt;br /&gt;
中身はほぼ同じだと思いますが、そちらについての説明はしません。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ubuntu 16.04&lt;/li&gt;
&lt;li&gt;Ansible 2.1.1.0&lt;/li&gt;
&lt;li&gt;nginx 1.10.1&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;

&lt;h3 id=&#34;certbot-のインストール&#34;&gt;certbot のインストール&lt;/h3&gt;

&lt;p&gt;certbot とは Let&amp;rsquo;s Encrypt の証明書の取得や更新を自動化するためのコマンドラインツールです。&lt;/p&gt;

&lt;p&gt;こんな感じの playbook でインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;- name: install certbot
  apt: name=letsencrypt state=present update_cache=yes
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;証明書の取得&#34;&gt;証明書の取得&lt;/h3&gt;

&lt;p&gt;certbot は &lt;a href=&#34;https://github.com/letsencrypt/acme-spec&#34;&gt;Automated Certificate Management Environment (ACME)&lt;/a&gt; というプロトコルにより証明書の取得を行います。&lt;br /&gt;
これは、Let&amp;rsquo;s Encrypt のサーバが証明書を取得しようとしているドメインのある URL にアクセスし、ちゃんとレスポンスを返すことができるかチェックするというものです。&lt;/p&gt;

&lt;p&gt;そのため事前に nginx 等の Web サーバを起動して、インターネットからリーチできる状態にしておく必要があります。&lt;br /&gt;
(&lt;code&gt;--standalone&lt;/code&gt; オプションを使えば certbot 自身が Web サーバを立ち上げてくれるが、すでに立っている Web サーバを止める必要があるので今回は使いませんでした)&lt;/p&gt;

&lt;p&gt;nginx の設定は以下のようにしておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
  listen 80;
  server_name blog.yuyat.jp;

  location /.well-known/ {
    default_type &amp;quot;text/plain&amp;quot;;
    root /var/www/html;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そして証明書を取得する playbook はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;- name: obtains cert keys
  command: letsencrypt certonly --webroot -d blog.yuyat.jp -w /var/www/html --email YOUR_EMAIL@example.com --agree-tos --keep-until-expiring --non-interactive
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-d&lt;/code&gt;: 取得対象のドメイン&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-w&lt;/code&gt;: Web サーバのルートディレクトリ (nginx.conf に合わせる)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--email&lt;/code&gt;: 自分のメールアドレス&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--agree-tos&lt;/code&gt;: &lt;a href=&#34;https://letsencrypt.org/repository/&#34;&gt;規約&lt;/a&gt;への同意の意思表示。自動化においては必須のコマンドです。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--keep-until-expiring&lt;/code&gt;: 証明書取得済みの場合、期限切れでなければ取得を行わない。Ansible で再実行するときのために必要です。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;証明書が取得できたら nginx に証明書の設定を追加します。&lt;br /&gt;
証明書ファイルはドメイン名に応じたパスに格納されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
  listen 443 ssl http2;
  server_name blog.yuyat.jp;

  ssl_certificate     /etc/letsencrypt/live/blog.yuyat.jp/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/blog.yuyat.jp/privkey.pem;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;証明書の自動更新&#34;&gt;証明書の自動更新&lt;/h3&gt;

&lt;p&gt;certbot には自動更新のためのサブコマンドも用意されています。&lt;br /&gt;
これを cron に登録しておくことで、証明書の有効期限を気にする必要がなくなります。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;- name: auto update cert keys
  cron:
    name: letsencrypt
    cron_file: letsencrypt
    user: root
    special_time: daily
    job: sh -c &#39;letsencrypt renew &amp;amp;&amp;amp; /usr/sbin/service nginx reload&#39; &amp;gt;&amp;gt; /var/log/letsencrypt/cron.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトだと &lt;code&gt;/usr/sbin&lt;/code&gt; には &lt;code&gt;$PATH&lt;/code&gt; が通ってないところに注意が必要です。&lt;/p&gt;

&lt;p&gt;実際には &lt;a href=&#34;https://github.com/kazuho/kaztools/blob/master/cronlog&#34;&gt;cronlog&lt;/a&gt; を使うなどしてうまく通知を受け取れるようにしておくのが良いでしょう。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugo で作ったサイトを CircleCI で GitHub Pages に自動デプロイ</title>
      <link>https://blog.yuyat.jp/post/auto-deploy-hugo-to-github-pages-with-circleci/</link>
      <pubDate>Mon, 19 Sep 2016 10:30:35 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/auto-deploy-hugo-to-github-pages-with-circleci/</guid>
      <description>

&lt;p&gt;Hugo は Jekyll と違って、GitHub Pages に push しても勝手にページ生成はされません。&lt;br /&gt;
どうにかして自分で Hugo を実行し、それで生成されたファイルを push する必要があります。&lt;br /&gt;
このブログを構築するにあたって、CircleCI でビルドして自動デプロイする手順がまとまったので公開します。&lt;/p&gt;

&lt;p&gt;なお、このブログはカスタムドメインを使用していますが、それについての説明はこの記事ではしません。&lt;/p&gt;

&lt;h2 id=&#34;前提とする環境&#34;&gt;前提とする環境&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Hugo Ver. 0.16&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;p&gt;以下のような環境・手順で自動デプロイが行われるようにします。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;記事のソースは &lt;code&gt;master&lt;/code&gt; ブランチに push する&lt;/li&gt;
&lt;li&gt;GitHub Pages 用のブランチには &lt;code&gt;gh-pages&lt;/code&gt; を使う&lt;/li&gt;
&lt;li&gt;&lt;code&gt;master&lt;/code&gt; ブランチが更新された時に &lt;code&gt;gh-pages&lt;/code&gt; が自動的に更新される&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;セットアップ手順&#34;&gt;セットアップ手順&lt;/h2&gt;

&lt;h3 id=&#34;対象ブランチの設定&#34;&gt;対象ブランチの設定&lt;/h3&gt;

&lt;p&gt;当然ですがリポジトリを準備します。&lt;/p&gt;

&lt;p&gt;そしてリポジトリの Settings から GitHub Pages の Source として &lt;code&gt;gh-pages&lt;/code&gt; を選択します。&lt;/p&gt;

&lt;p&gt;ただし、&lt;code&gt;gh-pages&lt;/code&gt; ブランチがない状態だと選択できないと思うので、その場合は手動でブランチだけ作るか、CircleCI によるデプロイが行われた後で行うと良いでしょう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/auto-deploy-hugo-to-github-pages-with-circleci/github-setting.png&#34; width=&#34;248&#34; height=&#34;222&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;デプロイキーの用意&#34;&gt;デプロイキーの用意&lt;/h3&gt;

&lt;p&gt;CircleCI は CI 対象のリポジトリを登録する時に、自動的に対象リポジトリの SSH キーを生成します。&lt;br /&gt;
が、これは read-only なので、今回の様に CircleCI から GitHub に push したい場合は使えません。&lt;br /&gt;
なので手動で生成し、登録する必要があります。&lt;/p&gt;

&lt;p&gt;鍵の生成については GitHub のドキュメント等を参照してください。&lt;br /&gt;
&lt;a href=&#34;https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/#generating-a-new-ssh-key&#34;&gt;Generating a new SSH key&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;生成したら GitHub リポジトリの Settings -&amp;gt; Deploy keys -&amp;gt; Add deploy key と進み、Key には生成した公開鍵ファイルの中身を貼り付け、Allow write access にチェックを入れてください。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/auto-deploy-hugo-to-github-pages-with-circleci/add-a-deploy-key.png&#34; width=&#34;311&#34; height=&#34;502&#34;&gt;&lt;/p&gt;

&lt;p&gt;また、CircleCI 側には秘密鍵を登録します。&lt;br /&gt;
Project Settings -&amp;gt; SSH Permissions -&amp;gt; Add SSH Key と進み、hostname には github.com、Private Key には秘密鍵の中身を貼り付けてください。&lt;br /&gt;
これで github.com へのデプロイ時にはこの鍵ファイルが使われるようになります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.yuyat.jp/images/auto-deploy-hugo-to-github-pages-with-circleci/add-an-ssh-key.png&#34; width=&#34;429&#34; height=&#34;289&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;デプロイスクリプトの用意&#34;&gt;デプロイスクリプトの用意&lt;/h3&gt;

&lt;p&gt;circle.yml は以下のようなものを準備します。&lt;br /&gt;
&lt;code&gt;master&lt;/code&gt; ブランチが更新された時はデプロイ用のスクリプトを実行するようになっています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;dependencies:
  pre:
  - wget https://github.com/spf13/hugo/releases/download/v0.16/hugo_0.16-1_amd64.deb
  - sudo dpkg -i hugo_0.16-1_amd64.deb

test:
  override:
    - &amp;quot;true&amp;quot;

deployment:
  production:
    branch: master
    commands:
    - ./scripts/deploy_production.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デプロイスクリプトは以下のようにします。&lt;br /&gt;
これを &lt;code&gt;scripts/deploy_production.sh&lt;/code&gt; という名前で保存して、忘れずに &lt;code&gt;chmod +x&lt;/code&gt; しておきましょう。&lt;br /&gt;
設定部分は環境変数でセットするようにしてあるので、コピペそのままで使えると思います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash -eux

if [ -z &amp;quot;${GIT_USER_NAME}&amp;quot; ]; then
  echo &amp;quot;Please set an env var GIT_USER_NAME&amp;quot;
  exit 1
fi

if [ -z &amp;quot;${GIT_USER_EMAIL}&amp;quot; ]; then
  echo &amp;quot;Please set an env var GIT_USER_EMAIL&amp;quot;
  exit 1
fi

GIT_REPO=&amp;quot;git@github.com:${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}.git&amp;quot;

git submodule init
git submodule update

remote=`git ls-remote --heads 2&amp;gt; /dev/null | grep gh-pages || true`

if [ -n &amp;quot;$remote&amp;quot; ]; then
  git clone -b gh-pages &amp;quot;${GIT_REPO}&amp;quot; public
  rm -rf public/*
else
  git init public
  cd public
  git checkout -b gh-pages
  git remote add origin &amp;quot;${GIT_REPO}&amp;quot;
  cd ..
fi

hugo
cd public
git config --global user.name &amp;quot;${GIT_USER_NAME}&amp;quot;
git config --global user.email &amp;quot;${GIT_USER_EMAIL}&amp;quot;
git add --all
git commit -m &#39;Update [ci skip]&#39;
git push -f origin gh-pages
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;環境変数は CircleCI の Project Settings から Environment Variables へと進んで、以下を登録します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;GIT_USER_NAME&lt;/code&gt;: git commit 時の名前&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GIT_USER_EMAIL&lt;/code&gt;: git commit 時のメールアドレス&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;いずれも普段使いの Git と同じ設定にするのが良いでしょう。&lt;/p&gt;

&lt;h3 id=&#34;hugo-をセットアップして-git-push&#34;&gt;Hugo をセットアップして git push&lt;/h3&gt;

&lt;p&gt;あとは Hugo のファイルを &lt;code&gt;git push&lt;/code&gt; すれば勝手にデプロイされます。&lt;br /&gt;
このとき以下の点に注意してください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;public&lt;/code&gt; ディレクトリは &lt;code&gt;.gitignore&lt;/code&gt; に入れておき、生成されたファイルはコミットしないようにする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;config.toml&lt;/code&gt; に &lt;code&gt;theme&lt;/code&gt; を設定する

&lt;ul&gt;
&lt;li&gt;本来コマンドラインオプションで渡すこともできるが、デプロイスクリプト中では指定していないので&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;こうして出来上がったのがこのブログです。&lt;br /&gt;
リポジトリは公開してあるので、気になる点があればチェックしてみてください。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/yuya-takeyama/blog.yuyat.jp&#34;&gt;https://github.com/yuya-takeyama/blog.yuyat.jp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Enjoy blogging!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ブログを Hugo でリニューアルした</title>
      <link>https://blog.yuyat.jp/post/brand-new-blog/</link>
      <pubDate>Mon, 19 Sep 2016 02:39:31 +0900</pubDate>
      
      <guid>https://blog.yuyat.jp/post/brand-new-blog/</guid>
      <description>&lt;p&gt;長年 Wordpress を使ってきたけどいい加減辛くなってきたので &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; に移行しました。&lt;/p&gt;

&lt;p&gt;過去ブログのデータ移行については過去に何度も挫折していて、結局リバースプロキシを使っていい感じに振り分けることにしました。&lt;br /&gt;
以前の記事 URL は基本的に全て生きているはずです。&lt;br /&gt;
コメントとかはできませんが。&lt;/p&gt;

&lt;p&gt;新ブログは GitHub Pages からリバースプロキシを介して配信しています。&lt;br /&gt;
Let&amp;rsquo;s Encrypt で SSL 化し、ついでに Nginx も HTTP2 化したので、その辺のネタはそのうちに書いていければと思ってます。&lt;/p&gt;

&lt;p&gt;あと、テーマは &lt;a href=&#34;https://github.com/chibicode&#34;&gt;@chibicode&lt;/a&gt; さんの &lt;a href=&#34;https://github.com/chibicode/hugo-theme-shiori&#34;&gt;hugo-theme-shiori&lt;/a&gt; をカスタマイズして使っています。&lt;/p&gt;

&lt;p&gt;今後ともよろしくお願いします。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>